{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15063def-86df-4356-bf7c-f28294c47e75",
   "metadata": {},
   "source": [
    "# Experiment 1: Breast repositioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b1fc5e-9393-40d6-96a4-f23c458cef6b",
   "metadata": {},
   "source": [
    "#### Author: \n",
    "Bruno De Santi, PhD\n",
    "#### Affiliation:\n",
    "Multi-modality Medical Imaging Lab (M3I Lab), University of Twente, Enschede, The Netherlands\n",
    "#### Date:\n",
    "20/09/2023\n",
    "#### Paper/Project Title:\n",
    "Automated three-dimensional image registration for longitudinal photoacoustic imaging (De Santi et al. 2023, JBO)\n",
    "#### GitHub:\n",
    "https://github.com/brunodesanti/muvinn-reg\n",
    "#### License:\n",
    "[Specify the license, e.g., MIT, GPL, etc.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de0a575-6f72-4845-88a4-244f1838300f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adee29d4-41c9-4a66-907b-fe601dcca274",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "abs_path = r'C:\\Users\\DeSantiB\\muvinn-reg'\n",
    "import sys\n",
    "sys.path.append(abs_path)\n",
    "\n",
    "from models import models\n",
    "from utils import processing as proc\n",
    "from utils import visualizing as vis\n",
    "from utils import evaluating as eva\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "import torch\n",
    "import time\n",
    "import scipy.ndimage as scnd\n",
    "import SimpleITK as sitk\n",
    "\n",
    "plot_flag = True # if one wants to plot figures\n",
    "save_flag = True # if one wants to save figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2896d75b-8838-49aa-9355-ea72f2210532",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Apply MUVINN-reg and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2468ba7c-8b3c-4093-9144-6e6c85fb0519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data path\n",
    "data_path = r'path\\to\\data'\n",
    "\n",
    "# Path to directory where landmarks are stored\n",
    "landmarks_path = r'C:\\Users\\DeSantiB\\muvinn-reg\\notebooks\\mevislab\\landmarks'\n",
    "\n",
    "# Load and pad fixed image\n",
    "fixed_acq = '01_01'\n",
    "fixed_path = data_path + os.path.sep + fixed_acq + '.npy'\n",
    "fixed_data = np.load(fixed_path, allow_pickle=True).item()\n",
    "fixed_image = proc.pad_rec(fixed_data[\"rec\"], ((3, 3), (3, 3),(3, 3)))\n",
    "\n",
    "# Pad depth map and cup mask\n",
    "depth_map = proc.pad_rec(fixed_data[\"depth_map\"], ((3, 3), (3, 3),(3, 3)))\n",
    "cup_mask = proc.pad_rec(fixed_data[\"cup_mask\"], ((3, 3), (3, 3),(3, 3)))\n",
    "\n",
    "# Processing fixed image for image visualization\n",
    "frangi_options_pp = dict()\n",
    "frangi_options_pp['sigmas'] = (2, 3, 4)\n",
    "frangi_options_pp['alpha'] = 0.5\n",
    "frangi_options_pp['beta'] = 0.5\n",
    "frangi_options_pp['gamma'] = 1\n",
    "frangi_options_pp['bw_flag'] = True  \n",
    "\n",
    "aim_options_pp = dict()\n",
    "aim_options_pp['half_size_win'] = 5\n",
    "aim_options_pp['min_sd'] = 0.1\n",
    "aim_options_pp['weights'] = (0.2, 0.8)\n",
    "\n",
    "_, _ , fixed_image_pp = proc.processing_vis(fixed_image, frangi_options_pp, aim_options_pp, gpu = 'cuda') \n",
    "\n",
    "# Plot and save fixed image MIPs\n",
    "if plot_flag:\n",
    "    plt.figure()\n",
    "    fig = vis.plot_mips(fixed_image_pp)\n",
    "    fig.tight_layout()\n",
    "    if save_flag:\n",
    "        fig.savefig(r'pp_image_{}.svg'.format(fixed_acq), dpi=600)\n",
    "        fig.savefig(r'pp_image_{}.png'.format(fixed_acq))\n",
    "            \n",
    "# Adaptive thresholding for vascular segmentation of fixed image\n",
    "ti = 0.008 # threshold at cup surface\n",
    "tf = 0.003 # threshold at maximum depth\n",
    "tau = 100 # decay rate\n",
    "fixed_mask = proc.segment_vessels(fixed_image_pp, depth_map, ti = ti, tf = tf, tau = tau)\n",
    "\n",
    "# Define sampling mask\n",
    "sample_mask = np.bitwise_and(scnd.binary_dilation(cup_mask, np.ones((3, 3, 3))), scnd.binary_dilation(fixed_mask, np.ones((1, 1, 1))))\n",
    "\n",
    "# Convert to CUDA tensor\n",
    "fixed_image_t = torch.FloatTensor(fixed_image).cuda()\n",
    "\n",
    "moving_acqs = ('02_01','03_01','04_01','05_01','06_01','07_01')\n",
    "for moving_acq in moving_acqs:\n",
    "    \n",
    "    # Load and pad moving image\n",
    "    moving_path = data_path + os.path.sep + moving_acq + '.npy'\n",
    "    moving_data = np.load(moving_path, allow_pickle = True).item() #item() to return each item in tuples\n",
    "    moving_image = proc.pad_rec(moving_data[\"rec\"], ((3, 3), (3, 3),(3, 3)))\n",
    "    \n",
    "    # Process moving image\n",
    "    _, _ , moving_image_pp = proc.processing_vis(moving_image, frangi_options_pp, aim_options_pp, gpu = 'cuda')\n",
    "\n",
    "    # Adaptive thresholding for vascular segmentation of moving image\n",
    "    moving_mask = proc.segment_vessels(moving_image_pp, depth_map, ti = ti, tf = tf, tau = tau)\n",
    "    \n",
    "    # Plot and save moving image MIPs\n",
    "    if plot_flag:\n",
    "        plt.figure()\n",
    "        fig = vis.plot_mips(moving_image_pp)\n",
    "        fig.tight_layout()\n",
    "        if save_flag:\n",
    "            fig.savefig(r'pp_image_{}.svg'.format(moving_acq), dpi=600)\n",
    "            fig.savefig(r'pp_image_{}.png'.format(moving_acq))\n",
    "            \n",
    "        # Plot and save RGB overlays before co-registration\n",
    "        plt.figure()\n",
    "        fig = vis.plot_aligned_mips(moving_image_pp, fixed_image_pp, alpha = 0.5)\n",
    "        fig.tight_layout()\n",
    "        if save_flag:\n",
    "            fig.savefig(r'overlay_pp_{}_{}.svg'.format(fixed_acq, moving_acq), dpi=600)\n",
    "            fig.savefig(r'overlay_pp_{}_{}.png'.format(fixed_acq, moving_acq))\n",
    "           \n",
    "    # Convert to CUDA tensor\n",
    "    moving_image_t = torch.FloatTensor(moving_image).cuda()\n",
    "    \n",
    "    # MUVINN-reg settings and parameters\n",
    "    kwargs = {}\n",
    "    kwargs['mask'] = sample_mask\n",
    "\n",
    "    # Number of epochs\n",
    "    kwargs['epochs'] = 20000\n",
    "    # Total number of points to be sampled each iteration\n",
    "    kwargs['batch_size'] = 200 * (5 ** 3)\n",
    "    \n",
    "    # Sigma values during optimization\n",
    "    kwargs['frangi_sigmas'] = np.array([12, 9, 5, 3, 1.5])\n",
    "    \n",
    "    # Epochs for each sigma as percentage of total number of epochs\n",
    "    frangi_interval = np.array([0.2, 0.2, 0.2, 0.2, 0.2]) \n",
    "    kwargs['frangi_epochs'] = np.insert(np.cumsum(np.floor(frangi_interval*kwargs['epochs']))[:-1],0,0)\n",
    "\n",
    "    # Data term loss function\n",
    "    kwargs['loss_function'] = 'ncc'\n",
    "    # Width of local patches around sampled points\n",
    "    kwargs['ncc_widths'] = 2.5*kwargs['frangi_sigmas']/100\n",
    "\n",
    "    # Regularization\n",
    "    kwargs['jacobian_regularization'] = True\n",
    "    kwargs['alpha_jacobian'] = 1\n",
    "    kwargs['hyper_regularization'] = False\n",
    "    kwargs['alpha_hyper'] = 0.25\n",
    "\n",
    "    # Network architecture\n",
    "    kwargs['layers'] = [3,300,300,300,300,300,300,3]\n",
    "    kwargs['omega'] = 30\n",
    "\n",
    "    # Optimizer settings\n",
    "    kwargs['optimizer'] = 'adam' \n",
    "    kwargs['lr'] = 5e-5\n",
    "    \n",
    "    # Decrease learning rate when decreasing sigma\n",
    "    kwargs['scheduler_ms'] = kwargs['frangi_epochs'] # MultiStepLR scheduler parameters\n",
    "    kwargs['scheduler_gamma'] = 0.95\n",
    "\n",
    "    # If true print results during optimization\n",
    "    kwargs['verbose'] = False \n",
    "    # Folder where to save verbose results if verbose is true\n",
    "    kwargs['save_folder'] = r'C:\\Users\\DeSantiB\\muvinn-reg\\notebooks\\verbose'\n",
    "    # Verbose interval in epochs\n",
    "    kwargs['log_interval'] = int(kwargs['epochs']/4)\n",
    "    \n",
    "    # Frangi parameters inside optimization\n",
    "    frangi_options = dict()\n",
    "    frangi_options['alpha'] = 0.5\n",
    "    frangi_options['beta'] = 0.5\n",
    "    frangi_options['gamma'] = 0.1\n",
    "    frangi_options['bw_flag'] = True # White voxels are vessels\n",
    "    kwargs['frangi_options'] = frangi_options\n",
    "    \n",
    "    # Adaptive intensity modulation parameters inside optimization\n",
    "    aim_options = dict()\n",
    "    aim_options['half_size_win'] = 5\n",
    "    aim_options['min_sd'] = 0.1\n",
    "\n",
    "    start_time = time.time()\n",
    "    # Initialize model\n",
    "    ImpReg = models.ImplicitRegistrator(moving_image_t, fixed_image_t, **kwargs)\n",
    "    # Run model optimization\n",
    "    ImpReg.train()\n",
    "    execution_time = time.time() - start_time\n",
    "    \n",
    "    # Save and plot loss curve\n",
    "    fig = plt.figure(figsize = (20,5))\n",
    "    plt.plot(ImpReg.data_loss_list) # loss curve\n",
    "    plt.xlim(xmin=0, xmax = kwargs['epochs'])\n",
    "    plt.ylim(ymin=-1, ymax = 0)\n",
    "    ax = plt.gca()\n",
    "    plt.grid()\n",
    "    fig.savefig(r'loss_muvinn_{}_{}.svg'.format(fixed_acq, moving_acq), dpi = 600)\n",
    "    fig.savefig(r'loss_muvinn_{}_{}.png'.format(fixed_acq, moving_acq))\n",
    "\n",
    "    # Tranform original moving image\n",
    "    transformed_image, transformed_mask = ImpReg(fixed_image.shape, moving_image_t, moving_mask, forward_batch_size = 50000)\n",
    "    \n",
    "    # Tranform processed moving image\n",
    "    transformed_image_pp = ImpReg(fixed_image.shape, torch.FloatTensor(moving_image_pp).cuda(), forward_batch_size = 50000) \n",
    "    \n",
    "    # Plot and save RGB overlays after co-registration\n",
    "    if plot_flag:\n",
    "        plt.figure()\n",
    "        fig = vis.plot_aligned_mips(transformed_image_pp, fixed_image_pp)\n",
    "        fig.tight_layout()\n",
    "        if save_flag:\n",
    "            fig.savefig(r'muvinn_overlay_{}_{}.svg'.format(fixed_acq, moving_acq), dpi = 600)\n",
    "            fig.savefig(r'muvinn_overlay_{}_{}.png'.format(fixed_acq, moving_acq))\n",
    "            \n",
    "    # Plot and save RGB overlays at different depths after co-registration\n",
    "    if plot_flag:\n",
    "        depths = (4, 2, 0)\n",
    "        figs = vis.plot_aligned_mips_depth(moving_image_pp, fixed_image_pp, depth_map, depths, alpha = 0.5)\n",
    "        if save_flag:\n",
    "            for i, fig in enumerate(figs):\n",
    "                fig.savefig(r'overlay_depth_{}_{}_{}.svg'.format(depths[i], fixed_acq, moving_acq), dpi = 600)\n",
    "                fig.savefig(r'overlay_depth_{}_{}_{}.png'.format(depths[i], fixed_acq, moving_acq))\n",
    "\n",
    "        figs = vis.plot_aligned_mips_depth(transformed_image_pp, fixed_image_pp, depth_map, depths, alpha = 0.5)\n",
    "        if save_flag:\n",
    "            for i, fig in enumerate(figs):\n",
    "                fig.savefig(r'muvinn_overlay_depth_{}_{}_{}.svg'.format(depths[i], fixed_acq, moving_acq), dpi = 600)\n",
    "                fig.savefig(r'muvinn_overlay_depth_{}_{}_{}.png'.format(depths[i], fixed_acq, moving_acq))\n",
    "        \n",
    "    # Quantitative evaluation\n",
    "    \n",
    "    # Before co-registration\n",
    "    images = dict()\n",
    "    images['fixed'] = fixed_image\n",
    "    images['moving'] = moving_image\n",
    "\n",
    "    masks = dict()\n",
    "    masks['fixed'] = fixed_mask\n",
    "    masks['moving'] = moving_mask\n",
    "\n",
    "    fixed_landmarks, moving_landmarks = eva.load_landmarks(landmarks_path, fixed_acq, moving_acq)\n",
    "    landmarks = dict()\n",
    "    landmarks['reg'] = fixed_landmarks\n",
    "    landmarks['gt'] = moving_landmarks\n",
    "\n",
    "    metrics_before = eva.similarity(images, masks, landmarks)\n",
    "    \n",
    "    # Save metrics before co-registration\n",
    "    np.save(r'metrics_before_{}_{}.npy'.format(fixed_acq, moving_acq), metrics_before) \n",
    "\n",
    "    # After co-registration\n",
    "    images = dict()\n",
    "    images['fixed'] = fixed_image\n",
    "    images['moving'] = transformed_image\n",
    "\n",
    "    masks = dict()\n",
    "    masks['fixed'] = fixed_mask\n",
    "    masks['moving'] = transformed_mask\n",
    "\n",
    "    # Transform landmarks\n",
    "    reg_landmarks, delta = eva.register_landmarks(ImpReg.network, fixed_landmarks, fixed_image.shape)\n",
    "    \n",
    "    landmarks = dict()\n",
    "    landmarks['reg'] = reg_landmarks\n",
    "    landmarks['gt'] = moving_landmarks\n",
    "    \n",
    "    # Export transformed landmarks as txt\n",
    "    if save_flag:\n",
    "        str_landmarks = str()\n",
    "        idx_landmark = 1\n",
    "        str_landmarks +=  '['\n",
    "        for landmark in reg_landmarks:\n",
    "            str_landmark = '(' + str(landmark[2]) + ' ' + str(landmark[1]) + ' ' + str(landmark[0]) + ')' + '  #{},'. format(idx_landmark)\n",
    "            str_landmarks +=  str_landmark\n",
    "            idx_landmark += 1\n",
    "        str_landmarks +=  ']'\n",
    "        with open('reg_points_{}_{}.txt'.format(fixed_acq, moving_acq), 'w') as f:\n",
    "            f.write(str_landmarks)\n",
    "\n",
    "    metrics_after = eva.similarity(images, masks, landmarks)\n",
    "    \n",
    "    # Save metrics after co-registration\n",
    "    np.save(r'metrics_after_{}_{}.npy'.format(fixed_acq, moving_acq), metrics_after) \n",
    "    \n",
    "    # Save execution time\n",
    "    np.save(r'execution_time_{}_{}.npy'.format(fixed_acq, moving_acq), execution_time)\n",
    "    \n",
    "    # Extract displacement field\n",
    "    coordinate_tensor = ImpReg.makeCoordinateTensor(fixed_image.shape)\n",
    "    displacement_field = eva.displacement_field(ImpReg.network, coordinate_tensor, fixed_image.shape, forward_batch_size = 30000)\n",
    "\n",
    "    # Mask displacement field using cup mask\n",
    "    displacement_field_x = displacement_field[:,:,:,0]\n",
    "    displacement_field_y = displacement_field[:,:,:,1]\n",
    "    displacement_field_z = displacement_field[:,:,:,2]\n",
    "    masked_displacement_field_x = np.zeros_like(displacement_field_x)\n",
    "    masked_displacement_field_y = np.zeros_like(displacement_field_x)\n",
    "    masked_displacement_field_z = np.zeros_like(displacement_field_x)\n",
    "    masked_displacement_field_x[np.where(cup_mask)] = displacement_field_x[np.where(cup_mask)]\n",
    "    masked_displacement_field_y[np.where(cup_mask)] = displacement_field_y[np.where(cup_mask)]\n",
    "    masked_displacement_field_z[np.where(cup_mask)] = displacement_field_z[np.where(cup_mask)]\n",
    "        \n",
    "    # Compute magnitude of displacement field\n",
    "    magnitude_displacement_field = np.sqrt(masked_displacement_field_x**2 + masked_displacement_field_y**2 + masked_displacement_field_z**2)\n",
    "    if save_flag:\n",
    "        # Save displacement field\n",
    "        np.save(r'mag_df_{}_{}.npy'.format(fixed_acq, moving_acq), np.float16(magnitude_displacement_field)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reg_env",
   "language": "python",
   "name": "reg_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
